{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper by [OpenAI](https://openai.com/) over the massive [new NLP machine learning model GPT3](https://arxiv.org/abs/2005.14165), with a whopping  $175 \\cdot 10^9$ parameters, hints at the energy requirements for training the model in a paragraph of the paper.\n",
    "    \n",
    "    \"Practical large-scale pre-training requires large amounts of computation, which is energy-intensive: training the GPT-3 175B consumed several thousand petaflop/s-days of compute during pre-training\"\n",
    "\n",
    "With this rough estimate and some public information on (best-case) energy efficiency for large scale computation, I tried to estimate the actual energy requirement using `julia` as unitful caclulator. The result of that can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best case efficiency:\n",
      "48000 PFLOPS hr\n",
      "1.6876e-5 PFLOPS W⁻¹\n",
      "2.8442758947617923 GWh\n",
      "Summit equivalent efficiency:\n",
      "48000 PFLOPS hr\n",
      "1.4668e-5 PFLOPS W⁻¹\n",
      "3.27242977911099 GWh\n"
     ]
    }
   ],
   "source": [
    "using Unitful\n",
    "Unitful.register(@__MODULE__);\n",
    "using Unitful.DefaultSymbols #default SI units\n",
    "using Unitful:d #days\n",
    "using Unitful:hr #hours\n",
    "@unit FLOPS \"FLOPS\" FLoatingPointOpPerSecond 1/s true #true gives us all the SI-prefixes.\n",
    "@unit Wh \"Wh\" WattHour 1*W*hr true\n",
    "\n",
    "# Practical large-scale pre-training requires large amounts of computation, which is energy-intensive: training the GPT-3\n",
    "# 175B consumed several thousand petaflop/s-days of compute during pre-training\n",
    "# Given from paper:\n",
    "# Low estimate\n",
    "PFLOPSdays = 2000PFLOPS*1d\n",
    "\n",
    "# Best case performance per watt\n",
    "# https://en.wikipedia.org/wiki/Performance_per_watt\n",
    "GFLOPSPerWatt = 16.876GFLOPS/W\n",
    "SummitEquiv = 14.668GFLOPS/W\n",
    "\n",
    "# Calculate the total Wh required.\n",
    "function totalWh(PFLOPSdays,GFLOPSPerWatt; doprint=false)\n",
    "\tPetaFLOPSHours = uconvert(PFLOPS*hr,PFLOPSdays)\n",
    "    doprint ? println(PetaFLOPSHours) : nothing\n",
    "\tPFLOPSPerWatt = uconvert(PFLOPS/W,GFLOPSPerWatt)\n",
    "    doprint ? println(PFLOPSPerWatt) : nothing\n",
    "\treturn uconvert(GWh, PetaFLOPSHours / PFLOPSPerWatt)\n",
    "end\n",
    "\n",
    "println(\"Best case efficiency:\")\n",
    "totWh2k = totalWh(PFLOPSdays,GFLOPSPerWatt,doprint=true)\n",
    "println(totWh2k)\n",
    "\n",
    "println(\"Summit equivalent efficiency:\")\n",
    "\n",
    "totWh2kSummit = totalWh(PFLOPSdays,SummitEquiv,doprint=true)\n",
    "println(totWh2kSummit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even **in the best case energy efficiency this model needed almost 3GWh to be trained**. For comparison that's the energy output of an average nuclear power plant fully dedicated to training this model for 3 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
